{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a34e812-6333-48b2-9a70-bcc718df054a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, logging\n",
    "\n",
    "def setup_logging(level=logging.INFO, to_stdout=True, include_name=True):\n",
    "    fmt = \"[%(asctime)s] %(levelname)s: \"\n",
    "    if include_name:\n",
    "        fmt += \"%(name)s: \"\n",
    "    fmt += \"%(message)s\"\n",
    "\n",
    "    handler = logging.StreamHandler(sys.stdout if to_stdout else sys.stderr)\n",
    "    handler.setFormatter(logging.Formatter(fmt))\n",
    "\n",
    "    root = logging.getLogger()\n",
    "    root.handlers.clear()\n",
    "    root.setLevel(level)\n",
    "    root.addHandler(handler)\n",
    "\n",
    "    logging.getLogger(\"transformers\").setLevel(logging.WARNING)\n",
    "    logging.getLogger(\"qdrant_client\").setLevel(logging.INFO)\n",
    "    logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "\n",
    "logger = logging.getLogger(__name__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ef34b63-20f8-41df-b8c2-ac9ea499e7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-24 09:41:19,691] INFO: __main__: CUDA available: True\n",
      "[2025-08-24 09:41:19,729] INFO: __main__: GPU name: NVIDIA A100 80GB PCIe\n",
      "[2025-08-24 09:41:19,732] INFO: __main__: FlashAttention2 available: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2363/1425495769.py:57: UserWarning: Api key is used with an insecure connection.\n",
      "  self.client = QdrantClient(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-24 09:41:20,071] INFO: __main__: Qdrant client initialized with URL: http://qdrant:6333\n",
      "[2025-08-24 09:41:20,073] INFO: __main__: Loading retrieval model: vidore/colqwen2.5-v0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f13e831b184427e9ba86bb4890fb54d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca62aadc0e8d4c96b09dce9cfb656cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-24 09:41:27,998] INFO: __main__: Retrieval loaded in 7.92s\n",
      "[2025-08-24 09:41:28,000] INFO: __main__: Processing PDF: sample1.pdf\n",
      "[2025-08-24 09:41:28,001] INFO: __main__: Converting PDF to images: sample1.pdf (dpi=150)\n",
      "[2025-08-24 09:41:29,037] INFO: __main__: pdf2image(sample1.pdf): 26 pages in 1.04s\n",
      "[2025-08-24 09:41:29,038] INFO: __main__: Added 26 pages from sample1.pdf\n",
      "[2025-08-24 09:41:29,039] INFO: __main__: Processing PDF: sample2.pdf\n",
      "[2025-08-24 09:41:29,040] INFO: __main__: Converting PDF to images: sample2.pdf (dpi=150)\n",
      "[2025-08-24 09:42:16,166] INFO: __main__: pdf2image(sample2.pdf): 256 pages in 47.13s\n",
      "[2025-08-24 09:42:16,167] INFO: __main__: Added 256 pages from sample2.pdf\n",
      "[2025-08-24 09:42:16,168] INFO: __main__: Creating embeddings for 282 pages from 2 PDFs... (batch_size=16, num_workers=8, prefetch_factor=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding pages (opt):   0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-24 09:42:21,240] INFO: __main__: [batch 000] bs=16 data_wait=0.001s compute=3.068s\n",
      "[2025-08-24 09:42:21,242] INFO: __main__: first_batch_total_latency=3.069s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding pages (opt):   6%|▌         | 1/18 [00:05<01:26,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-24 09:42:22,308] INFO: __main__: [batch 001] bs=16 data_wait=0.000s compute=1.062s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding pages (opt):  11%|█         | 2/18 [00:06<00:43,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-24 09:42:23,570] INFO: __main__: [batch 002] bs=16 data_wait=0.000s compute=1.259s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding pages (opt):  17%|█▋        | 3/18 [00:07<00:30,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-24 09:42:24,835] INFO: __main__: [batch 003] bs=16 data_wait=0.001s compute=1.261s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding pages (opt):  22%|██▏       | 4/18 [00:08<00:24,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-24 09:42:26,100] INFO: __main__: [batch 004] bs=16 data_wait=0.000s compute=1.262s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding pages (opt):  28%|██▊       | 5/18 [00:09<00:20,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-24 09:42:27,366] INFO: __main__: [batch 005] bs=16 data_wait=0.000s compute=1.264s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding pages (opt):  33%|███▎      | 6/18 [00:11<00:17,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-24 09:42:28,634] INFO: __main__: [batch 006] bs=16 data_wait=0.000s compute=1.265s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding pages (opt):  39%|███▉      | 7/18 [00:12<00:15,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-24 09:42:29,903] INFO: __main__: [batch 007] bs=16 data_wait=0.000s compute=1.266s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding pages (opt):  44%|████▍     | 8/18 [00:13<00:13,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-24 09:42:31,172] INFO: __main__: [batch 008] bs=16 data_wait=0.000s compute=1.265s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding pages (opt):  50%|█████     | 9/18 [00:15<00:11,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-24 09:42:32,441] INFO: __main__: [batch 009] bs=16 data_wait=0.000s compute=1.266s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding pages (opt):  56%|█████▌    | 10/18 [00:16<00:10,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-24 09:42:33,711] INFO: __main__: [batch 010] bs=16 data_wait=0.000s compute=1.269s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding pages (opt):  61%|██████    | 11/18 [00:17<00:09,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-24 09:42:34,981] INFO: __main__: [batch 011] bs=16 data_wait=0.000s compute=1.267s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding pages (opt):  67%|██████▋   | 12/18 [00:18<00:07,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-24 09:42:36,253] INFO: __main__: [batch 012] bs=16 data_wait=0.001s compute=1.269s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding pages (opt):  72%|███████▏  | 13/18 [00:20<00:06,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-24 09:42:37,524] INFO: __main__: [batch 013] bs=16 data_wait=0.000s compute=1.268s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding pages (opt):  78%|███████▊  | 14/18 [00:21<00:05,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-24 09:42:38,796] INFO: __main__: [batch 014] bs=16 data_wait=0.001s compute=1.268s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding pages (opt):  83%|████████▎ | 15/18 [00:22<00:03,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-24 09:42:40,068] INFO: __main__: [batch 015] bs=16 data_wait=0.000s compute=1.270s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding pages (opt):  89%|████████▉ | 16/18 [00:23<00:02,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-24 09:42:41,342] INFO: __main__: [batch 016] bs=16 data_wait=0.001s compute=1.270s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding pages (opt):  94%|█████████▍| 17/18 [00:25<00:01,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-24 09:42:42,368] INFO: __main__: [batch 017] bs=10 data_wait=0.000s compute=1.023s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding pages (opt): 100%|██████████| 18/18 [00:26<00:00,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-24 09:42:42,373] INFO: __main__: throughput: 10.76 images/sec, total=282\n",
      "[2025-08-24 09:42:42,374] INFO: __main__: Created embeddings for 282 pages from 2 PDFs\n",
      "[2025-08-24 09:42:42,384] INFO: __main__: Deleting existing collection: multi_pdf_documents\n",
      "[2025-08-24 09:42:42,548] INFO: __main__: Created collection multi_pdf_documents with multivector support\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-24 09:42:48,532] INFO: __main__: Qdrant upsert 256 pts in 3.72s\n",
      "[2025-08-24 09:42:49,281] INFO: __main__: Qdrant upsert 26 pts in 0.33s\n",
      "[2025-08-24 09:42:49,282] INFO: __main__: Stored total 282 embeddings in Qdrant\n",
      "[2025-08-24 09:42:49,319] INFO: __main__: All embeddings stored in Qdrant successfully\n",
      "[2025-08-24 09:42:49,496] INFO: __main__: Loading VLM model: Qwen/Qwen2.5-VL-32B-Instruct\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9858c0c3dbe94187baf21ce8f9adcd01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-24 09:43:06,875] INFO: __main__: VLM loaded in 17.38s\n",
      "[2025-08-24 09:43:06,877] INFO: __main__: ==== 前処理完了 ====\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers.utils.import_utils import is_flash_attn_2_available\n",
    "from colpali_engine.models import ColQwen2_5, ColQwen2_5_Processor\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, Qwen2_5_VLProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import (\n",
    "    Distance, VectorParams, PointStruct,\n",
    "    MultiVectorConfig, MultiVectorComparator\n",
    ")\n",
    "\n",
    "def log_env():\n",
    "    cuda = torch.cuda.is_available()\n",
    "    logger.info(f\"CUDA available: {cuda}\")\n",
    "    if cuda:\n",
    "        logger.info(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    logger.info(f\"FlashAttention2 available: {is_flash_attn_2_available()}\")\n",
    "\n",
    "# ---------- Qdrant----------\n",
    "class QdrantVectorStore:\n",
    "    def __init__(\n",
    "        self,\n",
    "        url: str = \"http://qdrant:6333\",\n",
    "        api_key: Optional[str] = None,\n",
    "        collection_name: str = \"colpali_documents\",\n",
    "        timeout: float = 120.0,\n",
    "        prefer_grpc: bool = True,\n",
    "        grpc_port: int = 6334,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        QdrantVectorStore の初期化\n",
    "\n",
    "        Args:\n",
    "            url (str): Qdrant サーバーのURL (デフォルト: http://qdrant:6333)\n",
    "            api_key (Optional[str]): APIキー\n",
    "            collection_name (str): コレクション名。RDBのテーブルのような概念\n",
    "            timeout (float): タイムアウト秒数\n",
    "            prefer_grpc (bool): RESTよりgRPCを優先して通信する（バイナリデータの転送で、高速・低レイテンシ）\n",
    "            grpc_port (int): gRPCポート番号 (デフォルト: 6334)\n",
    "        \"\"\"\n",
    "        self.collection_name = collection_name\n",
    "\n",
    "        #QdrantClientのインスタンス化\n",
    "        self.client = QdrantClient(\n",
    "            url=url,\n",
    "            api_key=api_key,\n",
    "            timeout=timeout,\n",
    "            prefer_grpc=prefer_grpc,\n",
    "            grpc_port=grpc_port,\n",
    "        )\n",
    "        logger.info(f\"Qdrant client initialized with URL: {url}\")\n",
    "\n",
    "    def create_collection(\n",
    "        self,\n",
    "        multivector_size: int = 256,\n",
    "        force_recreate: bool = True,\n",
    "        distance: Distance = Distance.COSINE,\n",
    "        comparator: MultiVectorComparator = MultiVectorComparator.MAX_SIM,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Qdrantにコレクションを作成するメソッド（マルチベクター対応）\n",
    "\n",
    "        Args:\n",
    "            multivector_size: 埋め込みモデルが出力するベクトルの次元数\n",
    "            force_recreate: Trueの場合、既存コレクションを削除して再作成\n",
    "            Distance.COSINE: 検索にコサイン類似度を使用\n",
    "            comparator(MultiVectorComparator.MAX_SIM): 複数のベクトルの中で一番スコアが高い(類似度が高い)ものを選ぶ\n",
    "\n",
    "        Raises:\n",
    "            Exception: コレクション作成時にエラーが発生した場合\n",
    "        \"\"\"\n",
    "        try:\n",
    "            exists = any(\n",
    "                col.name == self.collection_name\n",
    "                for col in self.client.get_collections().collections\n",
    "            )\n",
    "            if exists:\n",
    "                if force_recreate:\n",
    "                    logger.info(f\"Deleting existing collection: {self.collection_name}\")\n",
    "                    self.client.delete_collection(self.collection_name)\n",
    "                else:\n",
    "                    logger.info(f\"Collection {self.collection_name} already exists\")\n",
    "                    return\n",
    "                    \n",
    "            #コレクション作成メソッドの呼び出し\n",
    "            self.client.create_collection(\n",
    "                collection_name=self.collection_name,\n",
    "                vectors_config=VectorParams(\n",
    "                    size=multivector_size,\n",
    "                    distance=distance,\n",
    "                    multivector_config=MultiVectorConfig(comparator=comparator),\n",
    "                ),\n",
    "            )\n",
    "            logger.info(\n",
    "                f\"Created collection {self.collection_name} with multivector support\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error creating collection: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _to_multivector(self, embedding: Any) -> List[List[float]]:\n",
    "        \"\"\"\n",
    "        Qdrantにマルチベクターを登録する前処理\n",
    "        Embeddingの形状が1次元でも2次元でも、2次元リストに正規化する\n",
    "        \"\"\"\n",
    "        arr = (\n",
    "            #embeddingがTensorならCPUに移動し、fp32に変換したうえでNumPy配列にする\n",
    "            #Tensorでない場合、NumPy配列に変換し、精度をfp32に統一\n",
    "            embedding.detach().cpu().to(torch.float32).numpy()\n",
    "            if isinstance(embedding, torch.Tensor)\n",
    "            else np.array(embedding, dtype=np.float32)\n",
    "        )\n",
    "        #1次元のベクトルの場合[0.1, 0.2]、 2次元リストにラップして返す [[0.1, 0.2]]\n",
    "        if arr.ndim == 1:\n",
    "            return [arr.tolist()]\n",
    "        #2次元ベクトルの場合、そのままのpythonリストに変換して返す\n",
    "        if arr.ndim == 2:\n",
    "            return arr.tolist() \n",
    "        raise ValueError(f\"Unexpected embedding shape: {arr.shape}\")\n",
    "\n",
    "    def store_embeddings(\n",
    "        self,\n",
    "        embeddings: List[torch.Tensor],\n",
    "        metadata: List[Dict[str, Any]],\n",
    "        upsert_batch_size: int = 64,\n",
    "        wait: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Qdrantへembeddingをアップサート\n",
    "        \"\"\"\n",
    "        #embeddingsとmetadataの数が一致しているかをチェック\n",
    "        assert len(embeddings) == len(metadata), \"embeddings/metadata length mismatch\"\n",
    "\n",
    "        sent = 0\n",
    "        buf: List[PointStruct] = []\n",
    "\n",
    "        def flush(_points: List[PointStruct]):\n",
    "            \"\"\"\n",
    "            バッファに溜まったポイントをQdrantに送信する内部関数\n",
    "            ポイントはQdrantの基本単位で、1件のベクトルデータを表すレコード(id,ベクトル,メタデータ)。\n",
    "            バッファは複数のポイントを一時的に貯めておくリスト\n",
    "            \"\"\"\n",
    "            if not _points:\n",
    "                return\n",
    "            t0 = time.perf_counter()\n",
    "\n",
    "            # バッファに溜まったポイントをQdrantに一括送信\n",
    "            self.client.upsert(\n",
    "                collection_name=self.collection_name,\n",
    "                points=_points,\n",
    "                wait=wait, #False: WAL(ログ)への追記が終わった時点で次のバッファを送る → データファイルへの書き込み、インデックス更新はQdrant内で非同期処理\n",
    "            )\n",
    "            dt = time.perf_counter() - t0\n",
    "            logger.info(f\"Qdrant upsert {len(_points)} pts in {dt:.2f}s\")\n",
    "\n",
    "        try:\n",
    "            # embeddingとmetadataを1件ずつ処理\n",
    "            for i, (emb, meta) in enumerate(zip(embeddings, metadata)):\n",
    "                # embeddingを2次元リストに正規化\n",
    "                multivector = self._to_multivector(emb)\n",
    "                # Qdrantに送信可能な形式に変換。（id, ベクトル, メタデータ)=ポイント\n",
    "                pid = int(meta.get(\"global_page_num\", i))\n",
    "                buf.append(PointStruct(id=pid, vector=multivector, payload=meta))\n",
    "                # バッファがbatch_sizeに達したらQdrant送信\n",
    "                if len(buf) >= upsert_batch_size:\n",
    "                    flush(buf)\n",
    "                    sent += len(buf)\n",
    "                    buf = []\n",
    "            # ループ終了後に、余ったバッファがあれば送信\n",
    "            if buf:\n",
    "                flush(buf)\n",
    "                sent += len(buf)\n",
    "            logger.info(f\"Stored total {sent} embeddings in Qdrant\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error storing embeddings: {e}\")\n",
    "            raise\n",
    "\n",
    "    def search(\n",
    "        self,\n",
    "        query_embedding: torch.Tensor,\n",
    "        top_k: int = 3,\n",
    "        score_threshold: Optional[float] = None,\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        検索クエリの埋め込みベクトルを、Qdrantが受け付ける形式（2次元リスト）に変換する。\n",
    "        Qdrantで類似検索を実行して結果を整形して返す。\n",
    "    \n",
    "        Args:\n",
    "            query_embedding: 検索クエリの埋め込みベクトル\n",
    "            top_k: 上位何件を返すか（デフォルト: 3）\n",
    "            score_threshold : 類似度スコアのしきい値（低スコアを除外）\n",
    "        \n",
    "        Notes:\n",
    "            Qdrant API呼び出し時の主なパラメータ:\n",
    "              - collection_name: 検索対象のコレクション名\n",
    "              - query: 検索クエリベクトル（正規化済み）\n",
    "              - limit: 上位件数 (top_k)\n",
    "              - score_threshold: 類似度スコアのしきい値\n",
    "              - with_payload=True: 結果にペイロード（メタデータ）を含める\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # クエリ埋め込みをQdrantに渡せる形（2次元リスト）に正規化\n",
    "            query = self._to_multivector(query_embedding)\n",
    "            # Qdrantへ検索リクエストを送信\n",
    "            res = self.client.query_points(\n",
    "                collection_name=self.collection_name,\n",
    "                query=query,\n",
    "                limit=top_k,\n",
    "                score_threshold=score_threshold,\n",
    "                with_payload=True,\n",
    "            )\n",
    "            # 検索結果（id,スコア,メタデータ）を整形してPythonの辞書リストに変換\n",
    "            out = [\n",
    "                {\"id\": p.id, \"score\": float(p.score), \"payload\": p.payload}\n",
    "                for p in res.points\n",
    "            ]\n",
    "            logger.info(f\"Found {len(out)} results\")\n",
    "            return out\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during search: {e}\")\n",
    "            raise\n",
    "\n",
    "    def get_collection_info(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Qdrantのコレクション情報を取得\n",
    "    \n",
    "        Returns:\n",
    "            - name: コレクション名\n",
    "            - vectors_count: 登録されているベクトルの総数\n",
    "            - points_count: 登録されているポイントの総数\n",
    "            - status: コレクションの状態\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Qdrantからコレクション情報を取得\n",
    "            info = self.client.get_collection(self.collection_name)\n",
    "\n",
    "            # 必要な情報を辞書にまとめて返す\n",
    "            return {\n",
    "                \"name\": self.collection_name,\n",
    "                \"vectors_count\": info.vectors_count,\n",
    "                \"points_count\": info.points_count,\n",
    "                \"status\": info.status,\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error getting collection info: {e}\")\n",
    "            return {}\n",
    "\n",
    "# ----------MultiModalRAG----------\n",
    "class MultiModalRAG:\n",
    "    def __init__(\n",
    "        self,\n",
    "        retrieval_model_name: str = \"vidore/colqwen2.5-v0.2\", # 検索用埋め込みモデル\n",
    "        vlm_model_name: str = \"Qwen/Qwen2.5-VL-32B-Instruct\", # 回答生成に用いるVLMモデル\n",
    "        qdrant_url: str = \"http://qdrant:6333\", #QdrantサーバーのURL\n",
    "        qdrant_api_key: Optional[str] = None,\n",
    "        collection_name: str = \"colpali_documents\", # Qdrantコレクション名\n",
    "        use_qdrant: bool = True,\n",
    "        pdf_dpi: int = 150, # PDF→画像変換時の解像度\n",
    "        pdf_fmt: str = \"jpeg\", # PDF→画像変換時のフォーマット（jpegはI/O軽量）\n",
    "        use_pdftocairo: bool = True, # pdf画像変換で、pdftocairoを利用する(高品質なレンダリング)\n",
    "    ):\n",
    "        \"\"\"\n",
    "        MultiModalRAGクラスの初期化処理。\n",
    "        \"\"\"\n",
    "        self.retrieval_model_name = retrieval_model_name\n",
    "        self.vlm_model_name = vlm_model_name\n",
    "        self.use_qdrant = use_qdrant\n",
    "        self.pdf_dpi = pdf_dpi\n",
    "        self.pdf_fmt = pdf_fmt\n",
    "        self.use_pdftocairo = use_pdftocairo\n",
    "\n",
    "        self.retrieval_model = None\n",
    "        self.retrieval_processor = None\n",
    "\n",
    "        self.vlm_model = None\n",
    "        self.vlm_processor = None\n",
    "\n",
    "        self.vector_store = QdrantVectorStore(\n",
    "            url=qdrant_url,\n",
    "            api_key=qdrant_api_key,\n",
    "            collection_name=collection_name,\n",
    "            timeout=120.0,\n",
    "            prefer_grpc=True,\n",
    "            grpc_port=6334,\n",
    "        )\n",
    "\n",
    "        self.all_document_images: List[Image.Image] = [] # PDFから変換した画像リスト\n",
    "        self.all_document_metadata: List[Dict[str, Any]] = [] # 各画像に対応するメタデータ\n",
    "        self.all_document_embeddings: List[torch.Tensor] = [] # 各画像ベクトル\n",
    "        self.document_mapping: Dict[str, Dict[str, int]] = {} # PDF名ごとのページ範囲マッピング\n",
    "\n",
    "    # ---- モデル読み込み ----\n",
    "    def load_retrieval(self) -> None:\n",
    "        \"\"\"\n",
    "        検索用埋め込みモデル（ColQwen2.5）をロード\n",
    "        \"\"\"\n",
    "        logger.info(f\"Loading retrieval model: {self.retrieval_model_name}\")\n",
    "        t0 = time.perf_counter()\n",
    "\n",
    "        # 検索用埋め込みモデルをロード（検索用）\n",
    "        self.retrieval_model = ColQwen2_5.from_pretrained(\n",
    "            self.retrieval_model_name,\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            device_map=\"cuda:0\" if torch.cuda.is_available() else \"cpu\",\n",
    "            attn_implementation=\"flash_attention_2\" if is_flash_attn_2_available() else None, # FlashAttention2対応なら高速化を有効にする\n",
    "        ).eval()\n",
    "        # プロセッサをロード（入力画像/テキストを埋め込み入力形式に整形）\n",
    "        self.retrieval_processor = ColQwen2_5_Processor.from_pretrained(\n",
    "            self.retrieval_model_name,\n",
    "            use_fast=True\n",
    "        )\n",
    "        logger.info(f\"Retrieval loaded in {time.perf_counter() - t0:.2f}s\")\n",
    "\n",
    "    def load_vlm(self) -> None:\n",
    "        \"\"\"\n",
    "        回答生成に使用する視覚言語モデル（Qwen2.5-VL）とそのプロセッサをロード\n",
    "        \"\"\"\n",
    "        logger.info(f\"Loading VLM model: {self.vlm_model_name}\")\n",
    "        t0 = time.perf_counter()\n",
    "        # VLMモデル本体をロード（生成用）\n",
    "        self.vlm_model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "            self.vlm_model_name,\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            device_map=\"cuda:0\" if torch.cuda.is_available() else \"cpu\",\n",
    "            attn_implementation=\"flash_attention_2\" if is_flash_attn_2_available() else None, # FlashAttention2対応なら高速化を有効にする\n",
    "        ).eval()\n",
    "        \n",
    "        # 入力画像サイズの下限と上限を指定（ピクセル数ベース）\n",
    "        min_pixels = 256 * 28 * 28\n",
    "        max_pixels = 2048 * 28 * 28\n",
    "\n",
    "        # VLM用のプロセッサをロード（画像・テキストを入力形式に整形）\n",
    "        self.vlm_processor = Qwen2_5_VLProcessor.from_pretrained(\n",
    "            self.vlm_model_name,\n",
    "            min_pixels=min_pixels, \n",
    "            max_pixels=max_pixels,\n",
    "            use_fast=True\n",
    "        )\n",
    "        logger.info(f\"VLM loaded in {time.perf_counter() - t0:.2f}s\")\n",
    "\n",
    "    def pdf_to_images(self, pdf_path: str) -> List[Image.Image]:\n",
    "        \"\"\"\n",
    "        PDFファイルをページごとに画像へ変換する関数\n",
    "\n",
    "        Args:\n",
    "            pdf_path (str): 入力PDFファイルのパス\n",
    "            \n",
    "        Returns:\n",
    "            List[Image.Image]: 変換後の各ページ画像のリスト\n",
    "        \"\"\"\n",
    "        logger.info(f\"Converting PDF to images: {pdf_path} (dpi={self.pdf_dpi})\")\n",
    "        \n",
    "         # PDFファイルの存在チェック（なければ例外を投げる）\n",
    "        if not os.path.exists(pdf_path):\n",
    "            raise FileNotFoundError(f\"PDF file not found: {pdf_path}\")\n",
    "            \n",
    "        t0 = time.perf_counter()\n",
    "\n",
    "        # pdf2imageを使ってPDFを画像に変換\n",
    "        images = convert_from_path(\n",
    "            pdf_path,\n",
    "            dpi=self.pdf_dpi, # 解像度（dpi）\n",
    "            use_pdftocairo=self.use_pdftocairo, # pdftocairoを使うか（高速・正確)\n",
    "            fmt=self.pdf_fmt, #出力画像フォーマット（jpeg）\n",
    "        )\n",
    "        dt = time.perf_counter() - t0\n",
    "        logger.info(f\"pdf2image({os.path.basename(pdf_path)}): {len(images)} pages in {dt:.2f}s\")\n",
    "        return images\n",
    "\n",
    "    def process_multiple_pdfs(\n",
    "        self,\n",
    "        pdf_paths: List[str],\n",
    "        batch_size: int = 16,\n",
    "        num_workers: int = 8,\n",
    "        prefetch_factor: int = 2,\n",
    "        force_recreate_collection: bool = False,\n",
    "        upsert_batch_size: int = 256,\n",
    "        upsert_wait: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        複数のPDFファイルを読み込み、画像・メタデータ・ベクトルを生成して保持する\n",
    "        \n",
    "        Args:\n",
    "            pdf_paths (List[str]): 入力PDFファイルのパスリスト\n",
    "            batch_size (int): 埋め込み生成時のDataLoaderバッチサイズ\n",
    "            num_workers (int): DataLoaderで並列に使うワーカー数\n",
    "            prefetch_factor (int): 各ワーカーが先読みするバッチ数\n",
    "            force_recreate_collection (bool): TrueならQdrantコレクションを再作成\n",
    "            upsert_batch_size (int):  Qdrantへ送る“書き込みバッチ”の件数。store_embeddings() にそのまま引き継がれる。\n",
    "            upsert_wait (bool): False: WAL(ログ)への追記が終わった時点でレスポンス返却 → データファイルへの書き込みとインデックス更新はQdrant内で非同期処理\n",
    "        \"\"\"\n",
    "        if self.retrieval_model is None or self.retrieval_processor is None:\n",
    "            raise ValueError(\"Retrieval model not loaded. Call load_retrieval() first.\")\n",
    "\n",
    "        all_images: List[Image.Image] = []\n",
    "        all_metadata: List[Dict[str, Any]] = []\n",
    "        start_page = 0\n",
    "\n",
    "        for pdf_path in pdf_paths:\n",
    "            logger.info(f\"Processing PDF: {pdf_path}\")\n",
    "            # PDFファイルの存在確認（なければスキップ）\n",
    "            if not os.path.exists(pdf_path):\n",
    "                logger.warning(f\"PDF file not found: {pdf_path}\")\n",
    "                continue\n",
    "\n",
    "            # PDFをページごとに画像へ変換\n",
    "            images = self.pdf_to_images(pdf_path)\n",
    "            pdf_name = os.path.basename(pdf_path)\n",
    "\n",
    "            # ページ範囲を記録（ドキュメントマッピング用）\n",
    "            end_page = start_page + len(images)\n",
    "            self.document_mapping[pdf_name] = {\n",
    "                \"start_page\": start_page,\n",
    "                \"end_page\": end_page,\n",
    "                \"total_pages\": len(images),\n",
    "            }\n",
    "\n",
    "            # ページごとのメタデータを作成\n",
    "            metadata = [\n",
    "                {\n",
    "                    \"pdf_path\": pdf_path,\n",
    "                    \"pdf_name\": pdf_name,\n",
    "                    \"page_num\": i + 1, # PDF内のページ番号（1始まり）\n",
    "                    \"global_page_num\": start_page + i, # 全体での通しページ番号\n",
    "                    \"image_path\": f\"{pdf_name}_page_{i+1}.{self.pdf_fmt}\", # 変換後の画像ファイル名\n",
    "                }\n",
    "                for i in range(len(images))\n",
    "            ]\n",
    "\n",
    "            # 全体リストに追加(複数PDF分の変換データ)\n",
    "            all_images.extend(images)\n",
    "            all_metadata.extend(metadata)\n",
    "            start_page = end_page # 次のPDFのページ開始位置を更新\n",
    "            \n",
    "            logger.info(f\"Added {len(images)} pages from {pdf_name}\")\n",
    "\n",
    "        # PDFから画像に変換した結果をインスタンス変数に保存（後で埋め込み生成や検索に利用）\n",
    "        self.all_document_images = all_images\n",
    "        self.all_document_metadata = all_metadata\n",
    "\n",
    "        # 画像を埋め込みモデルの入力形式に変換するためのヘルパー関数\n",
    "        def collate_fn(batch_imgs: List[Image.Image]):\n",
    "            return self.retrieval_processor.process_images(batch_imgs)\n",
    "\n",
    "        # DataLoaderの設定（画像を埋め込みモデルに効率的に流し込み）\n",
    "        dl_kwargs = dict(\n",
    "            batch_size=max(1,batch_size),\n",
    "            shuffle=False, # 順序を固定（PDFのページ順を維持）\n",
    "            collate_fn=collate_fn, # 画像を埋め込みモデルの入力形式に変換する前処理関数\n",
    "            num_workers=num_workers, # データローダーのワーカー数\n",
    "            pin_memory=torch.cuda.is_available(),\n",
    "            persistent_workers=(num_workers > 0), # ワーカーを持続させる（エポックごとにワーカーを再作成しない）\n",
    "        )\n",
    "        if num_workers > 0:\n",
    "            dl_kwargs[\"prefetch_factor\"] = prefetch_factor # GPUに渡す次バッチを、CPUワーカーが先に用意しておく深さ。GPUを待たせないため・\n",
    "\n",
    "        dataloader = DataLoader(all_images, **dl_kwargs)\n",
    "\n",
    "        logger.info(\n",
    "            f\"Creating embeddings for {len(all_images)} pages from {len(pdf_paths)} PDFs...\"\n",
    "            f\" (batch_size={dl_kwargs['batch_size']}, num_workers={num_workers}\"\n",
    "            f\", prefetch_factor={prefetch_factor if num_workers>0 else 'n/a'})\"\n",
    "        )\n",
    "\n",
    "        # 行列演算の高速化設定（TF32を使った最適化）\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "        # 埋め込みを溜めるリスト\n",
    "        embeddings: List[torch.Tensor] = []\n",
    "        t0 = time.perf_counter()\n",
    "\n",
    "        first_batch_logged = False\n",
    "\n",
    "        # 画像のベクトル変換\n",
    "        with torch.inference_mode(), torch.amp.autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "            for bi, batch_images in enumerate(tqdm(dataloader, desc=\"Embedding pages (opt)\")):\n",
    "                t_start = time.perf_counter()\n",
    "                # GPUへ転送\n",
    "                batch_images = {\n",
    "                    k: v.to(self.retrieval_model.device, non_blocking=True)\n",
    "                    for k, v in batch_images.items()\n",
    "                }\n",
    "                t_ready = time.perf_counter()\n",
    "\n",
    "                # 画像のベクトル変換\n",
    "                out = self.retrieval_model(**batch_images)\n",
    "                t_done = time.perf_counter()\n",
    "\n",
    "                # バッチ出力を1件ずつ分解してリストに追加\n",
    "                embeddings.extend(torch.unbind(out))\n",
    "\n",
    "                data_wait = t_ready - t_start  # データ準備にかかった時間\n",
    "                compute = t_done - t_ready  # 推論計算にかかった時間\n",
    "                logger.info(f\"[batch {bi:03d}] bs={out.shape[0]} data_wait={data_wait:.3f}s compute={compute:.3f}s\")\n",
    "                if not first_batch_logged:\n",
    "                    logger.info(f\"first_batch_total_latency={t_done - t_start:.3f}s\")\n",
    "                    first_batch_logged = True\n",
    "\n",
    "        # CUDA環境ならGPUの処理が終わるまで同期\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "        t1 = time.perf_counter()\n",
    "        total = len(embeddings)\n",
    "        logger.info(f\"throughput: {total / (t1 - t0):.2f} images/sec, total={total}\")\n",
    "        self.all_document_embeddings = embeddings\n",
    "        logger.info(f\"Created embeddings for {total} pages from {len(pdf_paths)} PDFs\")\n",
    "\n",
    "        # 画像ベクトルをQdrantへ保存\n",
    "        if self.use_qdrant and self.vector_store and total > 0:\n",
    "            emb_dim = embeddings[0].shape[-1] # ベクトルの次元数を取得\n",
    "            self.vector_store.create_collection(\n",
    "                multivector_size=emb_dim,\n",
    "                force_recreate=force_recreate_collection,\n",
    "            )\n",
    "            # 画像ベクトルとメタデータをQdrantにバッチ送信\n",
    "            self.vector_store.store_embeddings(\n",
    "                embeddings, all_metadata,\n",
    "                upsert_batch_size=upsert_batch_size, # Qdrantへの書き込みバッチ件数\n",
    "                wait=upsert_wait,\n",
    "            )\n",
    "            logger.info(\"All embeddings stored in Qdrant successfully\")\n",
    "\n",
    "    def search_documents(self, query: str, top_k: int = 3) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        テキストクエリをベクトルに変換して Qdrantで類似検索し、検索結果を返す関数\n",
    "        \"\"\"\n",
    "        if self.retrieval_model is None or self.retrieval_processor is None:\n",
    "            raise ValueError(\"Retrieval model not loaded. Call load_retrieval() first.\")\n",
    "        # テキストクエリのベクトル変換\n",
    "        with torch.no_grad():\n",
    "            # クエリ文字列を前処理して、モデル入力形式に変換（トークナイズ）\n",
    "            proc = self.retrieval_processor.process_queries([query]).to(self.retrieval_model.device)\n",
    "            # 検索用埋め込みベクトルを生成\n",
    "            q_emb = self.retrieval_model(**proc)\n",
    "        # Qdrantに埋め込みを渡して類似検索を実行\n",
    "        hits = self.vector_store.search(q_emb[0], top_k=top_k)\n",
    "        results = []\n",
    "        # Qdrantの検索結果を整形\n",
    "        for h in hits:\n",
    "            meta = h[\"payload\"]\n",
    "            page_idx = int(meta.get(\"global_page_num\", h[\"id\"]))\n",
    "            results.append({\n",
    "                \"pdf_name\": meta[\"pdf_name\"],\n",
    "                \"pdf_path\": meta[\"pdf_path\"],\n",
    "                \"page_num\": meta[\"page_num\"],  # PDF内のページ番号（1始まり）\n",
    "                \"global_page_num\": meta[\"global_page_num\"],  # 全体ページ番号（通し番号）\n",
    "                \"score\": h[\"score\"],  # 類似度スコア\n",
    "                \"metadata\": meta,  # メタ情報\n",
    "                \"image\": self.all_document_images[page_idx] if 0 <= page_idx < len(self.all_document_images) else None, #画像\n",
    "            })\n",
    "        return results\n",
    "\n",
    "    def generate_answer(\n",
    "        self, question: str, search_results: List[Dict[str, Any]], max_new_tokens: int = 500\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        検索結果から画像を抽出して、ユーザーの質問と合わせてVLMに入力して回答を生成する\n",
    "        \"\"\"\n",
    "        if self.vlm_model is None or self.vlm_processor is None:\n",
    "            raise ValueError(\"VLM model not loaded. Call load_vlm() first.\")\n",
    "\n",
    "        # 検索結果から画像を抽出\n",
    "        imgs = [r[\"image\"] for r in search_results if r.get(\"image\") is not None]\n",
    "\n",
    "        # VLMに渡すチャット形式の入力を作成\n",
    "        chat_msgs = [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                # 検索結果の画像を順番に追加\n",
    "                *[{\"type\": \"image\", \"image\": img} for img in imgs],\n",
    "                # ユーザー質問をテキストとして追加\n",
    "                {\"type\": \"text\", \"text\": f\"以下の画像を参照して質問に答えてください：\\n\\n質問: {question}\\n\\n回答:\"}\n",
    "            ]\n",
    "        }]\n",
    "\n",
    "        # モデルが解釈できるチャットテンプレートに整形\n",
    "        text = self.vlm_processor.apply_chat_template(\n",
    "            chat_msgs, tokenize=False, add_generation_prompt=True\n",
    "        )\n",
    "        # チャットメッセージから画像入力だけを抽出\n",
    "        img_inputs, _ = process_vision_info(chat_msgs)\n",
    "\n",
    "        # プロセッサでテキストをトークナイズして、画像を前処理してテンソル化\n",
    "        inputs = self.vlm_processor(\n",
    "            text=[text],\n",
    "            images=img_inputs,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "        ).to(self.vlm_model.device)\n",
    "\n",
    "        # VLMで回答生成\n",
    "        with torch.no_grad():\n",
    "            gen_ids = self.vlm_model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                top_p=0.9,\n",
    "            )\n",
    "\n",
    "        # プロンプトを除外し、出力部分のみテキストに変換して表示\n",
    "        trimmed = [out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, gen_ids)]\n",
    "        decoded = self.vlm_processor.batch_decode(\n",
    "            trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "        )\n",
    "        return decoded[0].strip()\n",
    "\n",
    "class AdvancedQASystem:\n",
    "    def __init__(self, rag: MultiModalRAG):\n",
    "        self.rag = rag\n",
    "\n",
    "    def answer_question(self, question: str, top_k: int = 3, max_new_tokens: int = 500) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        ユーザーの質問に対して、検索と回答生成をまとめて実行する。\n",
    "        \n",
    "        Args:\n",
    "            question (str): ユーザーの質問（自然文）\n",
    "            top_k (int): 検索で取得する上位候補数\n",
    "            max_new_tokens (int): 回答生成の最大トークン数\n",
    "        \"\"\"\n",
    "        # 関連文書を検索\n",
    "        results = self.rag.search_documents(question, top_k=top_k)\n",
    "        \n",
    "        # 検索結果を基に回答を生成\n",
    "        answer = self.rag.generate_answer(question, results, max_new_tokens=max_new_tokens)\n",
    "\n",
    "        # 質問文・回答文・参照したソース情報（PDF名・ページ番号・スコア）を辞書で返す\n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"answer\": answer,\n",
    "            \"sources\": [\n",
    "                {\"pdf_name\": r[\"pdf_name\"], \"page_num\": r[\"page_num\"], \"score\": r[\"score\"]}\n",
    "                for r in results\n",
    "            ],\n",
    "        }\n",
    "\n",
    "# ----------エントリーポイント----------\n",
    "if __name__ == \"__main__\":\n",
    "    setup_logging(level=logging.INFO, to_stdout=True, include_name=True)  \n",
    "    log_env()\n",
    "\n",
    "    # MultiModalRAG のインスタンスを初期化\n",
    "    rag = MultiModalRAG(\n",
    "        use_qdrant=True,\n",
    "        qdrant_url=\"http://qdrant:6333\",\n",
    "        qdrant_api_key=\"colqwen25-qdrant-api-key\",\n",
    "        collection_name=\"multi_pdf_documents\",\n",
    "        pdf_dpi=150, # PDF→画像変換時の解像度（DPI）\n",
    "        pdf_fmt=\"jpeg\",\n",
    "        use_pdftocairo=True,\n",
    "    )\n",
    "\n",
    "    # 検索用モデルのみロード\n",
    "    rag.load_retrieval()\n",
    "\n",
    "    # サンプルPDFファイルを指定\n",
    "    pdf_paths = [\"sample1.pdf\", \"sample2.pdf\"]\n",
    "    \n",
    "    existing_pdfs = [p for p in pdf_paths if os.path.exists(p)]\n",
    "    # 実際に存在するPDFだけを対象にする\n",
    "    if not existing_pdfs:\n",
    "        logger.warning(\"No input PDFs found. Put your PDFs next to this script.\")\n",
    "    else:\n",
    "        # PDF群 → 画像変換 → 埋め込み生成 → Qdrantに保存\n",
    "        rag.process_multiple_pdfs(\n",
    "            existing_pdfs,\n",
    "            batch_size=16,           # DataLoaderのバッチサイズ\n",
    "            num_workers=8,            # DataLoaderの並列ワーカー数（CPUリソースに依存）\n",
    "            prefetch_factor=2,        # ワーカーごとの先読みバッチ数\n",
    "            force_recreate_collection=True, # 既存コレクションを削除して再作成\n",
    "            upsert_batch_size=256,    # Qdrantに送信するバッチサイズ\n",
    "            upsert_wait=False,        # Trueならアップサート完了を待つ\n",
    "        )\n",
    "\n",
    "        # 回答生成（VLM）が必要になった段階でロード\n",
    "        rag.load_vlm()\n",
    "\n",
    "        # QAシステムをラップするクラスを用意\n",
    "        qa = AdvancedQASystem(rag)\n",
    "\n",
    "        logger.info(\"==== 前処理完了 ====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10702800-788c-473f-bd2d-d5c182e599f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 開始: 28件の質問を処理します ===\n",
      "\n",
      "================================================================================\n",
      "【1/28】質問: 液晶モニター文書の主な内容は何ですか？\n",
      "--------------------------------------------------------------------------------\n",
      "[2025-08-24 09:43:07,034] INFO: __main__: Found 5 results\n",
      "【回答】\n",
      "### 回答:\n",
      "液晶モニター文書の主な内容は、以下のとおりです：\n",
      "\n",
      "1. **製品情報と説明**:\n",
      "   - 文書はLG製液晶モニター（モデル: IPS225V, IPS235V）に関する取扱説明書であり、購入者に対して感謝の意を表しています。\n",
      "   - 使用前に本取扱説明書をよく読んで保管することを推奨しています。\n",
      "\n",
      "2. **目次と構成**:\n",
      "   - 文書は以下の主要なセクションで構成されています：\n",
      "     - **組み立てと準備**: 同梱品、各部の名称、OSDメニューの説明、モニターの設置方法（スタンドの取り付け/取り外し、テーブルへの設置、壁への取り付け）。\n",
      "     - **モニターの接続**: PCへの接続方法（D-SUB接続、DVI-D接続、HDMI接続）。\n",
      "     - **設定の方法**: メインメニューへのアクセス、メニュー項目の変更方法、画質調整、モード設定、デュアルパッケージ設定など。\n",
      "     - **トラブルシューティング**: 問題解決のための対処方法。\n",
      "     - **仕様**: 製品の詳細仕様（\n",
      "\n",
      "【参照ソース】\n",
      "- sample1.pdf ページ1 (スコア:18.606)\n",
      "- sample1.pdf ページ2 (スコア:15.781)\n",
      "- sample2.pdf ページ4 (スコア:14.689)\n",
      "- sample1.pdf ページ12 (スコア:14.242)\n",
      "- sample1.pdf ページ4 (スコア:14.205)\n",
      "\n",
      "処理時間: 23.54秒\n",
      "進捗: 1/28 完了 (3.6%)\n",
      "\n",
      "================================================================================\n",
      "【2/28】質問: メニューの図において、明るさ、コントラスト、画質のそれぞれの数値を教えて下さい。\n",
      "--------------------------------------------------------------------------------\n",
      "[2025-08-24 09:43:30,617] INFO: __main__: Found 5 results\n",
      "【回答】\n",
      "### 回答:\n",
      "メニューの図において、明るさ、コントラスト、画質のそれぞれの数値は次のとおりです：\n",
      "\n",
      "- **明るさ (明るさ)**: **100**\n",
      "- **コントラスト**: **70**\n",
      "- **画質**: **5**\n",
      "\n",
      "これらの値は、OSD（On-Screen Display）メニューの「PICTURE」セクションで示されています。\n",
      "\n",
      "【参照ソース】\n",
      "- sample1.pdf ページ13 (スコア:26.353)\n",
      "- sample1.pdf ページ14 (スコア:25.555)\n",
      "- sample1.pdf ページ15 (スコア:21.874)\n",
      "- sample1.pdf ページ16 (スコア:21.090)\n",
      "- sample1.pdf ページ17 (スコア:20.778)\n",
      "\n",
      "処理時間: 10.76秒\n",
      "進捗: 2/28 完了 (7.1%)\n",
      "\n",
      "================================================================================\n",
      "【3/28】質問: モニターの角度について、何度に調整できますか？\n",
      "--------------------------------------------------------------------------------\n",
      "[2025-08-24 09:43:41,336] INFO: __main__: Found 5 results\n",
      "【回答】\n",
      "モニターの角度は、上下に **-5°～+15°** の範囲で調整できます。\n",
      "\n",
      "【参照ソース】\n",
      "- sample1.pdf ページ7 (スコア:20.780)\n",
      "- sample1.pdf ページ14 (スコア:17.717)\n",
      "- sample1.pdf ページ18 (スコア:17.679)\n",
      "- sample1.pdf ページ12 (スコア:17.621)\n",
      "- sample1.pdf ページ6 (スコア:17.615)\n",
      "\n",
      "処理時間: 6.54秒\n",
      "進捗: 3/28 完了 (10.7%)\n",
      "\n",
      "================================================================================\n",
      "【4/28】質問: MODE設定の画面において、ムービーのアイコンは左から何番目にある？\n",
      "--------------------------------------------------------------------------------\n",
      "[2025-08-24 09:43:47,889] INFO: __main__: Found 5 results\n",
      "【回答】\n",
      "### 質問: MODE設定の画面において、ムービーのアイコンは左から何番目にある？\n",
      "\n",
      "### 回答:\n",
      "MODE設定の画面において、ムービーのアイコンは左から **2番目** にあります。  \n",
      "\n",
      "**理由:**  \n",
      "MODE設定の画面には、以下のアイコンが表示されています（左から順に）：  \n",
      "1. ユーザー  \n",
      "2. ムービー  \n",
      "3. テキスト  \n",
      "4. 画像  \n",
      "5. sRGB  \n",
      "\n",
      "したがって、ムービーのアイコンは左から **2番目** です。  \n",
      "\n",
      "**最終回答:**\n",
      "**\\boxed{2}**\n",
      "\n",
      "【参照ソース】\n",
      "- sample1.pdf ページ18 (スコア:22.572)\n",
      "- sample1.pdf ページ5 (スコア:20.350)\n",
      "- sample1.pdf ページ17 (スコア:17.755)\n",
      "- sample1.pdf ページ12 (スコア:17.198)\n",
      "- sample1.pdf ページ16 (スコア:16.918)\n",
      "\n",
      "処理時間: 14.17秒\n",
      "進捗: 4/28 完了 (14.3%)\n",
      "\n",
      "================================================================================\n",
      "【5/28】質問: 動作温度は？\n",
      "--------------------------------------------------------------------------------\n",
      "[2025-08-24 09:44:02,016] INFO: __main__: Found 5 results\n",
      "【回答】\n",
      "### 質問: 動作温度は？\n",
      "\n",
      "### 回答:\n",
      "- **IPS225V**:  \n",
      "  動作温度は **10°C - 35°C** です。\n",
      "\n",
      "- **IPS235V**:  \n",
      "  動作温度は **10°C - 35°C** です。\n",
      "\n",
      "どちらのモデルでも動作温度範囲が同じであることが確認できます。\n",
      "\n",
      "【参照ソース】\n",
      "- sample1.pdf ページ23 (スコア:13.517)\n",
      "- sample1.pdf ページ22 (スコア:13.506)\n",
      "- sample2.pdf ページ70 (スコア:9.933)\n",
      "- sample1.pdf ページ9 (スコア:9.916)\n",
      "- sample2.pdf ページ179 (スコア:9.892)\n",
      "\n",
      "処理時間: 10.63秒\n",
      "進捗: 5/28 完了 (17.9%)\n",
      "\n",
      "================================================================================\n",
      "【6/28】質問: スタンドをモニターに接続する方法は？\n",
      "--------------------------------------------------------------------------------\n",
      "[2025-08-24 09:44:12,666] INFO: __main__: Found 5 results\n",
      "【回答】\n",
      "### 質問: スタンドをモニターに接続する方法は？\n",
      "\n",
      "### 回答:\n",
      "スタンドをモニターに接続する方法は以下の手順で行います。\n",
      "\n",
      "1. **モニターの準備**  \n",
      "   モニターの画面側を下にして、クッション性のある平面上に置きます。この際、モニターを傷つけないよう、フォームマットや柔らかい保護布を敷いておくことが推奨されます。\n",
      "\n",
      "2. **スタンドの取り付け**  \n",
      "   スタンドを取り付け、硬貨などでネジを右に回して締め付けます。\n",
      "\n",
      "#### 手順の詳細:\n",
      "- **ステップ 1**: モニターをクッション性のある平面に画面側を下にして置き、保護布などを敷きます。\n",
      "- **ステップ 2**: スタンド基部をモニター本体に合わせ、ネジを通します。\n",
      "- **ステップ 3**: 硬貨やネジレンチを使って、ネジを右に回してしっかり締め付けます。\n",
      "\n",
      "#### 注意事項:\n",
      "- モニターを傷つけないように、取り扱いには注意が必要です。\n",
      "- スタンドがしっかりと固定されていることを確認してください。\n",
      "\n",
      "### 参考画像:\n",
      "![スタンドの取り付け](attachment://image2.png)\n",
      "\n",
      "以上の手順に従って\n",
      "\n",
      "【参照ソース】\n",
      "- sample1.pdf ページ2 (スコア:19.013)\n",
      "- sample1.pdf ページ6 (スコア:18.551)\n",
      "- sample1.pdf ページ10 (スコア:18.038)\n",
      "- sample1.pdf ページ8 (スコア:17.284)\n",
      "- sample1.pdf ページ7 (スコア:17.268)\n",
      "\n",
      "処理時間: 23.48秒\n",
      "進捗: 6/28 完了 (21.4%)\n",
      "\n",
      "================================================================================\n",
      "【7/28】質問: モニター背面の接続端子の種類を教えて下さい。\n",
      "--------------------------------------------------------------------------------\n",
      "[2025-08-24 09:44:36,167] INFO: __main__: Found 5 results\n",
      "【回答】\n",
      "モニター背面の接続端子の種類は以下の通りです：\n",
      "\n",
      "1. **D-SUB**  \n",
      "   - 15ピンアナログ接続用（RGB OUT）。\n",
      "\n",
      "2. **DVI-D**  \n",
      "   - デジタル映像信号用。\n",
      "\n",
      "3. **HDMI**  \n",
      "   - デジタル映像および音声信号用。\n",
      "\n",
      "### 補足情報：\n",
      "- **D-SUB**：アナログ信号で映像を送信します。\n",
      "- **DVI-D**：デジタル信号で映像を送信します。\n",
      "- **HDMI**：デジタル信号で映像と音声を同時に送信します。  \n",
      "\n",
      "これらがモニター背面に配置されており、接続方法については説明書の詳細が記載されています。\n",
      "\n",
      "【参照ソース】\n",
      "- sample1.pdf ページ10 (スコア:21.351)\n",
      "- sample1.pdf ページ4 (スコア:21.096)\n",
      "- sample1.pdf ページ2 (スコア:19.931)\n",
      "- sample1.pdf ページ11 (スコア:19.307)\n",
      "- sample1.pdf ページ7 (スコア:18.880)\n",
      "\n",
      "処理時間: 15.63秒\n",
      "進捗: 7/28 完了 (25.0%)\n",
      "\n",
      "================================================================================\n",
      "【8/28】質問: 解像度の最小値と最大値は？\n",
      "--------------------------------------------------------------------------------\n",
      "[2025-08-24 09:44:51,775] INFO: __main__: Found 5 results\n",
      "【回答】\n",
      "### 質問: 解像度の最小値と最大値は？\n",
      "\n",
      "### 回答:\n",
      "解像度の最小値と最大値については、提供された資料から以下のようにまとめることができます。\n",
      "\n",
      "#### **1. IPS225V の解像度情報**\n",
      "- **最大解像度**:  \n",
      "  - D-SUB (アナログ): \\( 1920 \\times 1080 @ 60 \\, \\text{Hz} \\)\n",
      "  - DVI/HDMI (デジタル): \\( 1920 \\times 1080 @ 60 \\, \\text{Hz} \\)\n",
      "- **推奨解像度**:  \n",
      "  - VESA \\( 1920 \\times 1080 @ 60 \\, \\text{Hz} \\)\n",
      "\n",
      "最小解像度は明示的に記載されていませんが、一般的には VGA 解像度（\\( 640 \\times 480 \\)）やそれ以下の解像度もサポートしていることが想定されます。\n",
      "\n",
      "---\n",
      "\n",
      "#### **2. IPS235V の解像度情報**\n",
      "- **最大解像度**:  \n",
      "  - D-SUB (アナログ): \\( 1920 \\times 1080 @ 60 \\, \\text{Hz} \\)\n",
      "  - DVI/HDMI (デジタル):\n",
      "\n",
      "【参照ソース】\n",
      "- sample1.pdf ページ22 (スコア:17.343)\n",
      "- sample1.pdf ページ23 (スコア:17.087)\n",
      "- sample1.pdf ページ24 (スコア:15.413)\n",
      "- sample1.pdf ページ5 (スコア:14.475)\n",
      "- sample1.pdf ページ21 (スコア:14.208)\n",
      "\n",
      "処理時間: 23.69秒\n",
      "進捗: 8/28 完了 (28.6%)\n",
      "\n",
      "================================================================================\n",
      "【9/28】質問: スタンドを含めたモニタ全体の寸法は？\n",
      "--------------------------------------------------------------------------------\n",
      "[2025-08-24 09:45:15,474] INFO: __main__: Found 5 results\n",
      "【回答】\n",
      "### 質問: スタンドを含めたモニタ全体の寸法は？\n",
      "\n",
      "### 回答:\n",
      "スタンドを含めたモニタ全体の寸法は以下の通りです：\n",
      "\n",
      "#### **IPS225V**\n",
      "- **スタンド装着時**:\n",
      "  - 幅 (幅 x 高さ x 奥行): \\( 51.3 \\, \\text{cm} \\times 39.8 \\, \\text{cm} \\times 19.1 \\, \\text{cm} \\)\n",
      "\n",
      "#### **IPS235V**\n",
      "- **スタンド装着時**:\n",
      "  - 幅 (幅 x 高さ x 奥行): \\( 54.7 \\, \\text{cm} \\times 41.7 \\, \\text{cm} \\times 19.1 \\, \\text{cm} \\)\n",
      "\n",
      "### 結論:\n",
      "- **IPS225V**: \\( 51.3 \\, \\text{cm} \\times 39.8 \\, \\text{cm} \\times 19.1 \\, \\text{cm} \\)\n",
      "- **IPS235V**: \\( 54.7 \\, \\text{cm} \\times 41.7 \\, \\text{cm} \\times 19.1 \\, \\text{cm\n",
      "\n",
      "【参照ソース】\n",
      "- sample1.pdf ページ6 (スコア:17.642)\n",
      "- sample1.pdf ページ2 (スコア:17.247)\n",
      "- sample1.pdf ページ8 (スコア:16.859)\n",
      "- sample1.pdf ページ22 (スコア:16.853)\n",
      "- sample1.pdf ページ23 (スコア:16.597)\n",
      "\n",
      "処理時間: 23.50秒\n",
      "進捗: 9/28 完了 (32.1%)\n",
      "\n",
      "================================================================================\n",
      "【10/28】質問: Kensingtonセキュリティケーブルはどのようにして固定していますか？\n",
      "--------------------------------------------------------------------------------\n",
      "[2025-08-24 09:45:38,980] INFO: __main__: Found 5 results\n",
      "【回答】\n",
      "Kensington セキュリティケーブルは、以下の手順でモニターをテーブルに固定します。\n",
      "\n",
      "1. **Kensington セキュリティシステムコネクタの確認**:\n",
      "   - Kensington セキュリティシステムコネクタはモニターの背面にあります。\n",
      "   - コネクタの取り付けと使用方法の詳細については、Kensington セキュリティシステム付属の取扱説明書や公式サイト（http://www.kensington.com）を参照してください。\n",
      "\n",
      "2. **Kensington セキュリティシステムケーブルの接続**:\n",
      "   - Kensington セキュリティシステムケーブルをモニター背面のコネクタに接続します。\n",
      "   - モニターをテーブルに固定するために、ケーブルのもう一方を固定する対象物（例：テーブルのフックや専用ロックボックスなど）に取り付けます。\n",
      "\n",
      "### 図解からの補足：\n",
      "- 画像には、モニター背面にケーブルが接続されている様子が示されています。ケーブルは、モニターを移動防止のための固定装置に繋がれています。\n",
      "\n",
      "### 注意点：\n",
      "- モニターを設置する際には、適切な通気\n",
      "\n",
      "【参照ソース】\n",
      "- sample1.pdf ページ8 (スコア:20.379)\n",
      "- sample1.pdf ページ9 (スコア:13.741)\n",
      "- sample1.pdf ページ3 (スコア:13.598)\n",
      "- sample1.pdf ページ6 (スコア:13.010)\n",
      "- sample1.pdf ページ7 (スコア:12.892)\n",
      "\n",
      "処理時間: 23.53秒\n",
      "進捗: 10/28 完了 (35.7%)\n",
      "\n",
      "================================================================================\n",
      "【11/28】質問: 令和７年情報通信白書の主な内容は何ですか？\n",
      "--------------------------------------------------------------------------------\n",
      "[2025-08-24 09:46:02,514] INFO: __main__: Found 5 results\n",
      "【回答】\n",
      "### 質問: 令和７年情報通信白書の主な内容は何ですか？\n",
      "\n",
      "### 回答:\n",
      "令和７年情報通信白書は、日本の情報通信分野の現状、課題、および未来の方向性について詳細に分析した報告書です。その主な内容は以下の通りです。\n",
      "\n",
      "#### **第I部：特集 広がりゆく「社会基盤」としてのデジタル**\n",
      "1. **第1章 「社会基盤」としてのデジタルの浸透・拡大と動向**\n",
      "   - デジタル技術が社会基盤として果たす役割とその現在の状況。\n",
      "   - AIの進展や活用状況、海外事業者の台頭、日本の現状などを概観。\n",
      "   - 世界的な情勢や自然環境、社会の変化を踏まえ、今後のデジタル社会の見通しと課題を示す。\n",
      "\n",
      "2. **第2章 進展するデジタルがもたらす課題**\n",
      "   - デジタル技術の進展による課題（例えば、社会的不平等、セキュリティ問題、プライバシー保護など）を指摘。\n",
      "   - 自然環境や社会変化との関連性を分析し、解決策の必要性を強調。\n",
      "\n",
      "3. **第3章\n",
      "\n",
      "【参照ソース】\n",
      "- sample2.pdf ページ4 (スコア:22.583)\n",
      "- sample2.pdf ページ3 (スコア:22.385)\n",
      "- sample2.pdf ページ1 (スコア:22.175)\n",
      "- sample2.pdf ページ2 (スコア:21.774)\n",
      "- sample2.pdf ページ171 (スコア:19.936)\n",
      "\n",
      "処理時間: 23.81秒\n",
      "進捗: 11/28 完了 (39.3%)\n",
      "\n",
      "================================================================================\n",
      "【12/28】質問: 2014年から2024年にかけてLINE利用率が最も成長した年代は？\n",
      "--------------------------------------------------------------------------------\n",
      "[2025-08-24 09:46:26,339] INFO: __main__: Found 5 results\n",
      "【回答】\n",
      "### 質問: 2014年から2024年にかけてLINE利用率が最も成長した年代は？\n",
      "\n",
      "### 回答:\n",
      "2014年から2024年にかけて、LINE利用率が最も成長した年代は **60代** です。\n",
      "\n",
      "#### 理由:\n",
      "1. **図表 I-1-1-2（LINE利用率の推移）** を見ると、各年代別のLINE利用率の変化が示されています。\n",
      "   - 2014年における60代のLINE利用率は **11.3%** でしたが、2024年には **91.1%** に増加しています。\n",
      "   - 他の年代についても増加は見られますが、その伸び率や絶対値で比較すると、60代の成長が特に顕著です。\n",
      "\n",
      "2. **具体的な数値の比較**:\n",
      "   - 10代: 2014年は既に高水準であり、その後の伸びは緩やか。\n",
      "   - 20代: 同じく2014年からすでに高い利用率を維持しており、大きな変化は少ない。\n",
      "   - 30代・40代: 一定の増加は見られるものの、60代ほどの急激な成長は見られない。\n",
      "   - 5\n",
      "\n",
      "【参照ソース】\n",
      "- sample2.pdf ページ16 (スコア:25.754)\n",
      "- sample2.pdf ページ125 (スコア:21.083)\n",
      "- sample2.pdf ページ18 (スコア:20.566)\n",
      "- sample2.pdf ページ147 (スコア:20.292)\n",
      "- sample2.pdf ページ17 (スコア:20.135)\n",
      "\n",
      "処理時間: 23.94秒\n",
      "進捗: 12/28 完了 (42.9%)\n",
      "\n",
      "================================================================================\n",
      "【13/28】質問: 2020年以降、2番目に高い利用率の動画サービスは？\n",
      "--------------------------------------------------------------------------------\n",
      "[2025-08-24 09:46:50,283] INFO: __main__: Found 5 results\n",
      "【回答】\n",
      "### 質問: 2020年以降、2番目に高い利用率の動画サービスは？\n",
      "\n",
      "### 回答:\n",
      "2020年以降、2番目に高い利用率の動画サービスは **Netflix** です。\n",
      "\n",
      "### 理由:\n",
      "1. **図表 I-1-1-4** を確認すると、インターネットを利用した動画・ラジオサービスの利用率の推移が示されています。\n",
      "   - 2020年以降、利用率が高い順に以下のように推移しています：\n",
      "     1. **YouTube**（オンデマンド型の動画共有サービス）\n",
      "     2. **Netflix**（オンデマンド型の動画配信サービス）\n",
      "\n",
      "2. **図表 I-1-1-5** も確認すると、YouTubeとTikTokの利用率の推移が示されており、特に2020年以降、YouTubeの利用率は非常に高く、ほぼ全世代で8割を超える傾向が見られます。これにより、**YouTubeが最も高い利用率**を持つことがわかります。\n",
      "\n",
      "3. 次いで高い利用率を示しているのが **Netflix** です。図表I-1-1-4と図表I-1-1-5からも、Netflixの利用率は他の動画配信サービスと比べて著しく高いことが確認できます。\n",
      "\n",
      "###\n",
      "\n",
      "【参照ソース】\n",
      "- sample2.pdf ページ17 (スコア:22.350)\n",
      "- sample2.pdf ページ18 (スコア:21.893)\n",
      "- sample2.pdf ページ97 (スコア:20.594)\n",
      "- sample2.pdf ページ110 (スコア:20.178)\n",
      "- sample2.pdf ページ39 (スコア:20.144)\n",
      "\n",
      "処理時間: 23.75秒\n",
      "進捗: 13/28 完了 (46.4%)\n",
      "\n",
      "================================================================================\n",
      "【14/28】質問: ニュース目的のソーシャルメディア利用率において、全年代でトップのメディアは何？\n",
      "--------------------------------------------------------------------------------\n",
      "[2025-08-24 09:47:14,032] INFO: __main__: Found 5 results\n",
      "【回答】\n",
      "### 質問:\n",
      "ニュース目的のソーシャルメディア利用率において、全年代でトップのメディアは何？\n",
      "\n",
      "### 回答:\n",
      "ニュース目的のソーシャルメディア利用率において、全年代でトップのメディアは **YouTube** です。\n",
      "\n",
      "### 理由:\n",
      "1. **図表 I-1-1-8** を参照すると、「ニュース目的のソーシャルメディア利用率（年代別、日本の全回答者、2024年）」が示されています。\n",
      "   - 全年代（総合値）における各ソーシャルメディアの利用率を比較すると、YouTubeの利用率が最も高いことが分かります。\n",
      "\n",
      "2. **具体的な数値**:\n",
      "   - 全年代でのYouTubeのニュース目的利用率为約 **66%** （総合値）。\n",
      "   - これに対し、X (Twitter)、LINE、Facebookなどの他のソーシャルメディアはそれぞれ約 **53%**、**21%**、**19%** と、YouTubeに大きく劣っています。\n",
      "\n",
      "3. **年代別の分析**:\n",
      "   - 各年代（10代～70代以上）においても、YouTubeの利用率が他メディアを上回っており、特に若年層（10代～20代）では突出しています。\n",
      "\n",
      "### 結論:\n",
      "ニュース目的のソーシャルメディア利用率において\n",
      "\n",
      "【参照ソース】\n",
      "- sample2.pdf ページ19 (スコア:24.905)\n",
      "- sample2.pdf ページ132 (スコア:22.857)\n",
      "- sample2.pdf ページ18 (スコア:21.953)\n",
      "- sample2.pdf ページ131 (スコア:21.077)\n",
      "- sample2.pdf ページ20 (スコア:20.261)\n",
      "\n",
      "処理時間: 23.76秒\n",
      "進捗: 14/28 完了 (50.0%)\n",
      "\n",
      "================================================================================\n",
      "【15/28】質問: 海外プラットフォーム事業者の売上高で最も成長性しているのは？\n",
      "--------------------------------------------------------------------------------\n",
      "[2025-08-24 09:47:37,783] INFO: __main__: Found 5 results\n",
      "【回答】\n",
      "### 質問: 海外プラットフォーム事業者の売上高で最も成長性の高いのは？\n",
      "\n",
      "### 回答:\n",
      "海外プラットフォーム事業者の売上高で最も成長性が著しいのは、**Google** です。\n",
      "\n",
      "#### 理由:\n",
      "1. **図表 I-1-3-1 (第3節の図表)**:\n",
      "   - この図表は、海外の主要なデジタルプラットフォーム事業者の売上高の推移を示しています。\n",
      "   - Googleの売上高は、他の企業よりも顕著な成長曲線を描いており、全体的に突出しています。\n",
      "\n",
      "2. **市場動向 (第6節の内容)**:\n",
      "   - 図表 II-1-6-1（世界のICT市場における時価総額上位15社の変遷）では、AppleがMicrosoftを抜き、2024年には首位に立っています。しかし、この成長もGoogleの持続的な成長と比較すると、短期的な変動の影響が大きいと考えられます。\n",
      "   - プラットフォーム事業者の長期的な成長性を見ると、Googleが他社を圧倒的に上回っていることが分かります。\n",
      "\n",
      "3. **AI関連の先進性 (第3節の内容)**:\n",
      "   - 図表 I-1-3-3\n",
      "\n",
      "【参照ソース】\n",
      "- sample2.pdf ページ36 (スコア:23.335)\n",
      "- sample2.pdf ページ108 (スコア:21.578)\n",
      "- sample2.pdf ページ38 (スコア:21.071)\n",
      "- sample2.pdf ページ107 (スコア:20.791)\n",
      "- sample2.pdf ページ10 (スコア:19.500)\n",
      "\n",
      "処理時間: 23.75秒\n",
      "進捗: 15/28 完了 (53.6%)\n",
      "\n",
      "================================================================================\n",
      "【16/28】質問: 日本における生成AI導入に際しての懸念事項で最も多いものは？\n",
      "--------------------------------------------------------------------------------\n",
      "[2025-08-24 09:48:01,540] INFO: __main__: Found 5 results\n",
      "【回答】\n",
      "日本における生成AI導入に際しての懸念事項で最も多いものは、「効果的な活用方法がわからない」です。\n",
      "\n",
      "### 詳細:\n",
      "- **出典**: 図表 I-1-2-15（生成AI導入に際しての懸念事項 - 国別）。\n",
      "- **データ**:\n",
      "  - 日本では、「効果的な活用方法がわからない」が最も多く、約 **30.1%** と示されています。\n",
      "  - 次いで「社内情報の漏えい等のセキュリティリスク」や「ランニングコストがかかる」「初期コストがかかる」などが挙げられていますが、これらは「効果的な活用方法がわからない」と比較すると比率が低くなっています。\n",
      "\n",
      "この結果から、日本では生成AIの導入において、具体的な活用方法や戦略の不明瞭さが最も大きな懸念事項となっていることがわかります。\n",
      "\n",
      "【参照ソース】\n",
      "- sample2.pdf ページ35 (スコア:23.518)\n",
      "- sample2.pdf ページ146 (スコア:22.191)\n",
      "- sample2.pdf ページ32 (スコア:21.740)\n",
      "- sample2.pdf ページ33 (スコア:20.921)\n",
      "- sample2.pdf ページ52 (スコア:20.889)\n",
      "\n",
      "処理時間: 18.57秒\n",
      "進捗: 16/28 完了 (57.1%)\n",
      "\n",
      "================================================================================\n",
      "【17/28】質問: 生成AI関連市場の市場構成図について解説してください。\n",
      "--------------------------------------------------------------------------------\n",
      "[2025-08-24 09:48:20,098] INFO: __main__: Found 5 results\n",
      "【回答】\n",
      "### 解説：生成AI関連市場の市場構成図\n",
      "\n",
      "生成AI関連市場の市場構造は、3つの主要なレイヤーに整理されています。それぞれのレイヤーは、ユーザー層、アプリケーション層、モデル層、インフラストラクチャー層から構成されます。以下で詳細に解説します。\n",
      "\n",
      "---\n",
      "\n",
      "#### **1. ユーザー（事業者、一般消費者）**\n",
      "- **位置付け**：\n",
      "  - 生成AI関連市場の最上層。\n",
      "  - 使用する最終ユーザーがここに含まれます。\n",
      "  - 事業者や一般消費者が生成AIのサービスを利用します。\n",
      "- **利用例**：\n",
      "  - テキスト生成、コード生成、画像生成、動画生成、音声生成などのサービスを使用します。\n",
      "\n",
      "---\n",
      "\n",
      "#### **2. アプリケーション層**\n",
      "- **役割**：\n",
      "  - ユーザーが直接アクセスする生成AIのサービスを提供する層です。\n",
      "  - 特定の用途に特化したアプリケーションが含まれます。\n",
      "- **具体的なサービス**：\n",
      "  - テキスト生成（例：文章作成支援ツール）\n",
      "  - コード生成（例：プログラミング支援ツール）\n",
      "  - 画像生成（例：AIによるアート制作ツール）\n",
      "  - 動画生成（例：自動編集ツ\n",
      "\n",
      "【参照ソース】\n",
      "- sample2.pdf ページ38 (スコア:20.412)\n",
      "- sample2.pdf ページ118 (スコア:18.571)\n",
      "- sample2.pdf ページ66 (スコア:18.463)\n",
      "- sample2.pdf ページ119 (スコア:18.220)\n",
      "- sample2.pdf ページ10 (スコア:17.415)\n",
      "\n",
      "処理時間: 23.74秒\n",
      "進捗: 17/28 完了 (60.7%)\n",
      "\n",
      "================================================================================\n",
      "【18/28】質問: DX・イノベーション加速プラン2030はどのような図を表していますか？\n",
      "--------------------------------------------------------------------------------\n",
      "[2025-08-24 09:48:43,849] INFO: __main__: Found 5 results\n",
      "【回答】\n",
      "DX・イノベーション加速プラン2030は、以下のような図（図表 II-2-1-1）を表しています。\n",
      "\n",
      "### **図表の内容概要**\n",
      "1. **目指すべき目標と課題**:\n",
      "   - 人口減少社会において、イノベーションを創出し、経済成長を実現するためには、AIの活用をはじめとする「社会DX」の加速化が不可欠。\n",
      "   - 地方でのDX推進や「地方創生2.0」を達成するため、「光電融合技術」を活用した「オール光ネットワーク」を中心とした新しいデジタルインフラの実現が求められる。\n",
      "   - 海外展開を進める中で、デジタルインフラの技術・システムの競争力を強化することが重要。\n",
      "\n",
      "2. **実現に向けての戦略**:\n",
      "   - **(1) AI社会を支えるデジタルインフラの整備**:\n",
      "     - オール光ネットワークの社会実装\n",
      "     - ワイヤレスセンサの地方分散化\n",
      "     - 衛星通信等の非地上系ネットワークの展開\n",
      "     - 光ファイバー・5Gの整備\n",
      "     - リモートセンシングを含めたデジタルインフラ活用の推進\n",
      "\n",
      "【参照ソース】\n",
      "- sample2.pdf ページ159 (スコア:23.584)\n",
      "- sample2.pdf ページ163 (スコア:17.111)\n",
      "- sample2.pdf ページ173 (スコア:16.765)\n",
      "- sample2.pdf ページ175 (スコア:16.707)\n",
      "- sample2.pdf ページ242 (スコア:16.537)\n",
      "\n",
      "処理時間: 23.78秒\n",
      "進捗: 18/28 完了 (64.3%)\n",
      "\n",
      "================================================================================\n",
      "【19/28】質問: テレワークの導入形態においてサテライトオフィス勤務は何%になっていますか？AIによるリスク例の体系的な分類案において、経済活動に関するリスクを挙げてください。\n",
      "--------------------------------------------------------------------------------\n",
      "[2025-08-24 09:49:07,714] INFO: __main__: Found 5 results\n",
      "【回答】\n",
      "### 質問に対する回答\n",
      "\n",
      "#### 1. **テレワークの導入形態においてサテライトオフィス勤務は何%になっていますか？**\n",
      "\n",
      "**図表 II-1-11-22**（「テレワーク導入率の推移」）を見ると、2024年におけるテレワークの導入形態について以下の情報が記載されています。\n",
      "\n",
      "- **在宅勤務**: 90.9%\n",
      "- **モバイルワーク**: 32.4%\n",
      "- **サテライトオフィス勤務**: 15.7%\n",
      "- **ワーケーション**: 0.9%\n",
      "\n",
      "よって、**サテライトオフィス勤務の割合は15.7%**です。\n",
      "\n",
      "---\n",
      "\n",
      "#### 2. **AIによるリスク例の体系的な分類案において、経済活動に関するリスクを挙げてください。**\n",
      "\n",
      "**図表 I-2-2-1**（「AIによるリスク例の体系的な分類案」）を見ると、「社会的リスク」のうち「経済活動に関するリスク」の項目が以下のように記載されています。\n",
      "\n",
      "- **知的財産権等の侵害**\n",
      "- **金銭的損失**\n",
      "- **機密情報の流出**\n",
      "- **労働者の失業**\n",
      "- **データや利益の集中**\n",
      "-\n",
      "\n",
      "【参照ソース】\n",
      "- sample2.pdf ページ51 (スコア:32.163)\n",
      "- sample2.pdf ページ157 (スコア:31.645)\n",
      "- sample2.pdf ページ139 (スコア:30.702)\n",
      "- sample2.pdf ページ138 (スコア:30.483)\n",
      "- sample2.pdf ページ146 (スコア:29.956)\n",
      "\n",
      "処理時間: 23.93秒\n",
      "進捗: 19/28 完了 (67.9%)\n",
      "\n",
      "================================================================================\n",
      "【20/28】質問: 米国の民間情報化投資は日本と比較してどのように遷移していますか？\n",
      "--------------------------------------------------------------------------------\n",
      "[2025-08-24 09:49:31,556] INFO: __main__: Found 5 results\n",
      "【回答】\n",
      "### 回答:\n",
      "\n",
      "米国と日本の民間情報化投資の遷移を比較すると、以下の特徴が見られます。\n",
      "\n",
      "#### 1. **米国の民間情報化投資の動向**:\n",
      "- 図表Ⅱ-1-1-7（日米の民間情報化投資の比較）によると、米国の民間情報化投資は、長期的に一貫して増加傾向にあります。\n",
      "- 投資額は、時間の経過とともに着実に上昇しており、特に2005年以降、急激な成長が見られます。\n",
      "- 2023年の投資額は1,722兆円（指数化値）に達しており、過去20年間で顕著な成長を遂げています。\n",
      "\n",
      "#### 2. **日本の民間情報化投資の動向**:\n",
      "- 同じ図表Ⅱ-1-1-7によると、日本の民間情報化投資も増加しているものの、その成長率は米国と比べて緩やかです。\n",
      "- 2023年の投資額は約1,400兆円（指数化値）であり、米国に比べて低い水準を維持しています。\n",
      "- 日本の情報化投資は、一貫して横ばい傾向にあり、急激な成長は見られません。\n",
      "\n",
      "#### 3.\n",
      "\n",
      "【参照ソース】\n",
      "- sample2.pdf ページ69 (スコア:22.544)\n",
      "- sample2.pdf ページ68 (スコア:20.060)\n",
      "- sample2.pdf ページ74 (スコア:18.225)\n",
      "- sample2.pdf ページ142 (スコア:18.064)\n",
      "- sample2.pdf ページ35 (スコア:17.957)\n",
      "\n",
      "処理時間: 23.76秒\n",
      "進捗: 20/28 完了 (71.4%)\n",
      "\n",
      "================================================================================\n",
      "【21/28】質問: インターネット利用時に不安を感じないひとの割合は？\n",
      "--------------------------------------------------------------------------------\n",
      "[2025-08-24 09:49:55,317] INFO: __main__: Found 5 results\n",
      "【回答】\n",
      "### 回答:\n",
      "インターネット利用時に不安を感じないひとの割合は **10.4%** です。\n",
      "\n",
      "### 解説:\n",
      "この情報は、図表Ⅱ-1-11-5「インターネット利用時に不安を感じる人の割合」から得られます。以下がその詳細です:\n",
      "\n",
      "1. **図表Ⅱ-1-11-5の内容**:\n",
      "   - 不安を感じない人: **10.4%**\n",
      "   - 不安を感じる人: **27.6%**\n",
      "   - どちらかといえば不安を感じない人: **17.7%**\n",
      "   - どちらかといえば不安を感じる人: **44.0%**\n",
      "\n",
      "2. **まとめ**:\n",
      "   図表から直接読み取れるように、インターネット利用時に**不安を感じないひとの割合は10.4%**と明示されています。\n",
      "\n",
      "したがって、**回答は10.4%**です。\n",
      "\n",
      "【参照ソース】\n",
      "- sample2.pdf ページ126 (スコア:24.003)\n",
      "- sample2.pdf ページ127 (スコア:22.709)\n",
      "- sample2.pdf ページ124 (スコア:18.852)\n",
      "- sample2.pdf ページ54 (スコア:18.590)\n",
      "- sample2.pdf ページ125 (スコア:18.470)\n",
      "\n",
      "処理時間: 18.20秒\n",
      "進捗: 21/28 完了 (75.0%)\n",
      "\n",
      "================================================================================\n",
      "【22/28】質問: グローバルICT市場の国・地域別シェアの推計（カテゴリー別）（2023年）において、クラウドの米国シェアは？\n",
      "--------------------------------------------------------------------------------\n",
      "[2025-08-24 09:50:13,571] INFO: __main__: Found 5 results\n",
      "【回答】\n",
      "グローバル ICT 市場の国・地域別シェアの推計（カテゴリー別）（2023年）におけるクラウド（A1クラウド）の米国シェアは **70%** です。この情報は、図表 I-1-3-7 から読み取ることができます。\n",
      "\n",
      "具体的には：\n",
      "- 図表 I-1-3-7 の「A1クラウド」行を見ると、米国のシェアが **70%** と記載されています。\n",
      "- 米国は緑色で示されており、その部分が最も広い範囲を占めています。\n",
      "\n",
      "したがって、回答は次の通りです：\n",
      "\n",
      "**回答: 70%**\n",
      "\n",
      "【参照ソース】\n",
      "- sample2.pdf ページ40 (スコア:35.794)\n",
      "- sample2.pdf ページ41 (スコア:33.705)\n",
      "- sample2.pdf ページ115 (スコア:31.464)\n",
      "- sample2.pdf ページ66 (スコア:30.855)\n",
      "- sample2.pdf ページ107 (スコア:30.825)\n",
      "\n",
      "処理時間: 15.36秒\n",
      "進捗: 22/28 完了 (78.6%)\n",
      "\n",
      "================================================================================\n",
      "【23/28】質問: 海底ケーブルの使用帯域幅の推移において、コンテンツプロバイダーはどのように遷移していますか？\n",
      "--------------------------------------------------------------------------------\n",
      "[2025-08-24 09:50:28,907] INFO: __main__: Found 5 results\n",
      "【回答】\n",
      "海底ケーブルの使用帯域幅の推移において、コンテンツプロバイダーの遷移について説明します。\n",
      "\n",
      "### **1. 2010年代前半までの状況**\n",
      "- **主導者**: 主に通信事業者（インターネットバックボーンプロバイダ）による海底ケーブルの敷設と利用が主流であり、コンテンツプロバイダによる海底ケーブル使用帯域は2011年には全体の **10%にも満たなかった**。\n",
      "- **理由**: この時期は、大規模なデータ伝送やネットワークインフラを必要とするコンテンツプロバイダ（例えばGoogleやMetaのような企業）がまだ海底ケーブルへの投資を積極的に行っていなかったため、使用帯域幅も比較的小さかった。\n",
      "\n",
      "---\n",
      "\n",
      "### **2. 2010年代後半以降の変化**\n",
      "- **ビッグテック企業の参入**: 2010年代後半から、Google、Meta、Microsoft、Amazonといったビッグテック企業が海底ケーブルの敷設と利用を拡大し始めた。これらの企業は、通信インフラ効率化やコスト削減を目的に自社で海底ケーブルを敷設する動きを見せ始めました。\n",
      "- **コンテンツプロバイダの使用帯域幅の増加**: 2\n",
      "\n",
      "【参照ソース】\n",
      "- sample2.pdf ページ37 (スコア:29.212)\n",
      "- sample2.pdf ページ244 (スコア:25.143)\n",
      "- sample2.pdf ページ66 (スコア:23.694)\n",
      "- sample2.pdf ページ47 (スコア:23.222)\n",
      "- sample2.pdf ページ164 (スコア:22.699)\n",
      "\n",
      "処理時間: 23.79秒\n",
      "進捗: 23/28 完了 (82.1%)\n",
      "\n",
      "================================================================================\n",
      "【24/28】質問: 日本のデータセンターサービス市場規模（売上高）の推移予測において、前年比成長率はどのように遷移していますか？\n",
      "--------------------------------------------------------------------------------\n",
      "[2025-08-24 09:50:52,703] INFO: __main__: Found 5 results\n",
      "【回答】\n",
      "### 回答:\n",
      "\n",
      "日本のデータセンターサービス市場規模（売上高）の前年比成長率について、以下に詳細を説明します。\n",
      "\n",
      "#### 1. **図表の確認**\n",
      "   - 図表 II-1-8-2 は「日本のデータセンターサービス市場規模（売上高）の推移及び予測」を示しています。\n",
      "   - 横軸は年（2023年～2028年）、縦軸は売上高（十億円）と前年比成長率（％）が表示されています。\n",
      "\n",
      "#### 2. **前年比成長率の遷移**\n",
      "   - **2023年**:\n",
      "     - 売上高は実績値として5,736億円（2兆7,361億円の誤記として読み替え可能）。\n",
      "     - 前年比成長率は約26.1％（ただし、図表では具体的な数値は表示されていません）。\n",
      "   - **2024年**:\n",
      "     - 売上高は4,142.3億円（推定値）。\n",
      "     - 前年比成長率は約26.1％（予測値）。\n",
      "   - **2025\n",
      "\n",
      "【参照ソース】\n",
      "- sample2.pdf ページ114 (スコア:34.454)\n",
      "- sample2.pdf ページ116 (スコア:32.970)\n",
      "- sample2.pdf ページ112 (スコア:29.947)\n",
      "- sample2.pdf ページ86 (スコア:29.690)\n",
      "- sample2.pdf ページ115 (スコア:29.634)\n",
      "\n",
      "処理時間: 23.80秒\n",
      "進捗: 24/28 完了 (85.7%)\n",
      "\n",
      "================================================================================\n",
      "【25/28】質問: 世界のICT市場における時価総額上位15社の変遷において、2025年に向上した企業を教えてもらえますか？\n",
      "--------------------------------------------------------------------------------\n",
      "[2025-08-24 09:51:16,515] INFO: __main__: Found 5 results\n",
      "【回答】\n",
      "### 回答:\n",
      "2025年における世界のICT市場における時価総額上位15社の変遷において、**向上した企業**は以下の通りです。\n",
      "\n",
      "#### 1. **Apple**\n",
      "   - 2024年から2025年にかけて、Appleが時価総額で首位に浮上しています。これにより、Appleは市場動向において顕著な成長を遂げました。\n",
      "\n",
      "#### 2. **NVIDIA**\n",
      "   - NVIDIAも2025年において時価総額で向上しており、特に生成AI向けの半導体需要拡大が評価された結果、2位に浮上しています。\n",
      "\n",
      "#### 3. **Microsoft**\n",
      "   - Microsoftは引き続き上位に位置していますが、AppleやNVIDIAの急成長により順位が変動しました。\n",
      "\n",
      "#### 4. **Amazon.com**\n",
      "   - Amazon.comも時価総額で向上し、引き続きクラウドサービスとeコマースの強みを発揮しています。\n",
      "\n",
      "#### 5. **Alphabet/Google**\n",
      "   - Alphabet/Googleは検索エンジンなどの主力事業により、安定した評価を維持し、順位を保っています。\n",
      "\n",
      "#### 6. **Meta Platforms/Facebook**\n",
      "   - Meta Platforms/FacebookもSNSの強みを活かして時価総額で\n",
      "\n",
      "【参照ソース】\n",
      "- sample2.pdf ページ107 (スコア:33.901)\n",
      "- sample2.pdf ページ67 (スコア:29.505)\n",
      "- sample2.pdf ページ66 (スコア:28.794)\n",
      "- sample2.pdf ページ76 (スコア:28.492)\n",
      "- sample2.pdf ページ36 (スコア:28.439)\n",
      "\n",
      "処理時間: 23.99秒\n",
      "進捗: 25/28 完了 (89.3%)\n",
      "\n",
      "================================================================================\n",
      "【26/28】質問: 我が国の周波数帯ごとの主な用途と電波の特徴の図は何を表していますか？\n",
      "--------------------------------------------------------------------------------\n",
      "[2025-08-24 09:51:40,484] INFO: __main__: Found 5 results\n",
      "【回答】\n",
      "### 回答:\n",
      "\n",
      "我が国の周波数帯ごとの主な用途と電波の特徴を示した図は、以下の内容を表しています。\n",
      "\n",
      "1. **周波数帯の分類と電波の特性**:\n",
      "   - 周波数帯が低いほど（超長波～短波）：\n",
      "     - 電波は障害物を回り込む能力が高い。\n",
      "     - 伝送できる情報量が少ない。\n",
      "     - 利用技術が比較的簡単。\n",
      "   - 周波数帯が高いほど（ミリ波～サブミリ波）：\n",
      "     - 電波は直進性が強くなる。\n",
      "     - 降雨や障害物により弱められる。\n",
      "     - 伝送できる情報量が大きい。\n",
      "     - 利用技術が高度で難しい。\n",
      "\n",
      "2. **周波数帯ごとの名称と範囲**:\n",
      "   - **超長波 (VLF)**: 100km～10km（3kHz～30kHz）\n",
      "   - **長波 (LF)**: 10km～1km（30kHz～300kHz）\n",
      "   - **中波 (MF)**: 1km～100m（300kHz～3MHz）\n",
      "   - **短波 (HF)**: 100m～1\n",
      "\n",
      "【参照ソース】\n",
      "- sample2.pdf ページ98 (スコア:29.221)\n",
      "- sample2.pdf ページ178 (スコア:26.176)\n",
      "- sample2.pdf ページ179 (スコア:25.470)\n",
      "- sample2.pdf ページ180 (スコア:24.948)\n",
      "- sample2.pdf ページ181 (スコア:24.869)\n",
      "\n",
      "処理時間: 23.77秒\n",
      "進捗: 26/28 完了 (92.9%)\n",
      "\n",
      "================================================================================\n",
      "【27/28】質問: 衛星・HAPSによる通信サービスの提供イメージの図は何を表していますか？\n",
      "--------------------------------------------------------------------------------\n",
      "[2025-08-24 09:52:04,227] INFO: __main__: Found 5 results\n",
      "【回答】\n",
      "### 回答:\n",
      "\n",
      "衛星・HAPS（High Altitude Platform Station）による通信サービスの提供イメージの図は、異なる高度での通信技術（衛星とHAPS）がどのように地上や航空機、船舶、災害対策、IoTなど幅広い分野で利用されるのかを示しています。以下にその内容を詳細に説明します。\n",
      "\n",
      "---\n",
      "\n",
      "#### 1. **図の構成要素**\n",
      "- **宇宙ステーション・宇宙旅客機**: 最上部に位置し、宇宙から地球をカバーする通信システムを示しています。\n",
      "- **3種類の通信技術**:\n",
      "  - **GEO (Geostationary Orbit)**:\n",
      "    - 高度: 約36,000km\n",
      "    - 地上エリア半径: 約1,000km～\n",
      "    - 特徴: 地球の自転に同期しているため、特定の地域を定点でカバーできる。\n",
      "  - **LEO (Low Earth Orbit)**:\n",
      "    - 高度: 数百～2,000km\n",
      "    - 地上エリア半径: 数百km～\n",
      "    - 特徴: 低高度で短い伝送遅延を持つため、高速かつ大容量の通信が可能。\n",
      "  - **HAPS**:\n",
      "    - 高度:\n",
      "\n",
      "【参照ソース】\n",
      "- sample2.pdf ページ87 (スコア:24.830)\n",
      "- sample2.pdf ページ177 (スコア:20.785)\n",
      "- sample2.pdf ページ49 (スコア:19.596)\n",
      "- sample2.pdf ページ81 (スコア:19.555)\n",
      "- sample2.pdf ページ86 (スコア:19.072)\n",
      "\n",
      "処理時間: 23.69秒\n",
      "進捗: 27/28 完了 (96.4%)\n",
      "\n",
      "================================================================================\n",
      "【28/28】質問: 日本のデータセンターの設置状況（地域別サーバールーム面積）において100,000㎡以上の地域はどこですか？\n",
      "--------------------------------------------------------------------------------\n",
      "[2025-08-24 09:52:27,970] INFO: __main__: Found 5 results\n",
      "【回答】\n",
      "### 質問: 日本のデータセンターの設置状況（地域別サーバールーム面積）において100,000㎡以上の地域はどこですか？\n",
      "\n",
      "### 回答:\n",
      "日本国内でサーバールーム面積が **100,000㎡以上** のデータセンターが設置されている地域は、以下の図表から確認できます。\n",
      "\n",
      "#### **図表 I-2-1-1 日本のデータセンターの設置状況（地域別サーバールーム面積）**\n",
      "この図表には、日本の地図上で各地域のサーバールーム面積が色分けで示されています。具体的な色の説明は次のとおりです：\n",
      "- **青色の部分**: 100,000㎡以上のサーバールーム面積を持つ地域\n",
      "\n",
      "#### **具体的な地域**\n",
      "図表によると、サーバールーム面積が **100,000㎡以上** の地域は **東京圏** に集中しています。特に、東京首都圏（東京都および周辺の神奈川県・埼玉県・千葉県など）に多くのデータセンターが立地していることがわかります。\n",
      "\n",
      "---\n",
      "\n",
      "### 結論:\n",
      "**日本のデータセンターの設置状況において、サーバールーム面積が100,00\n",
      "\n",
      "【参照ソース】\n",
      "- sample2.pdf ページ47 (スコア:32.779)\n",
      "- sample2.pdf ページ114 (スコア:26.843)\n",
      "- sample2.pdf ページ164 (スコア:24.968)\n",
      "- sample2.pdf ページ40 (スコア:24.587)\n",
      "- sample2.pdf ページ86 (スコア:24.265)\n",
      "\n",
      "処理時間: 23.76秒\n",
      "進捗: 28/28 完了 (100.0%)\n",
      "\n",
      " 全ての質問の処理が完了しました\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"液晶モニター文書の主な内容は何ですか？\",\n",
    "    \"メニューの図において、明るさ、コントラスト、画質のそれぞれの数値を教えて下さい。\",\n",
    "    \"モニターの角度について、何度に調整できますか？\",\n",
    "    \"MODE設定の画面において、ムービーのアイコンは左から何番目にある？\",\n",
    "    \"動作温度は？\",\n",
    "    \"スタンドをモニターに接続する方法は？\",\n",
    "    \"モニター背面の接続端子の種類を教えて下さい。\",\n",
    "    \"解像度の最小値と最大値は？\",\n",
    "    \"スタンドを含めたモニタ全体の寸法は？\",\n",
    "    \"Kensingtonセキュリティケーブルはどのようにして固定していますか？\",        \n",
    "    \"令和７年情報通信白書の主な内容は何ですか？\",\n",
    "    \"2014年から2024年にかけてLINE利用率が最も成長した年代は？\",\n",
    "    \"2020年以降、2番目に高い利用率の動画サービスは？\",\n",
    "    \"ニュース目的のソーシャルメディア利用率において、全年代でトップのメディアは何？\",\n",
    "    \"海外プラットフォーム事業者の売上高で最も成長性しているのは？\",\n",
    "    \"日本における生成AI導入に際しての懸念事項で最も多いものは？\",\n",
    "    \"生成AI関連市場の市場構成図について解説してください。\",\n",
    "    \"DX・イノベーション加速プラン2030はどのような図を表していますか？\",\n",
    "    \"テレワークの導入形態においてサテライトオフィス勤務は何%になっていますか？\"\n",
    "    \"AIによるリスク例の体系的な分類案において、経済活動に関するリスクを挙げてください。\",\n",
    "    \"米国の民間情報化投資は日本と比較してどのように遷移していますか？\",\n",
    "    \"インターネット利用時に不安を感じないひとの割合は？\",\n",
    "    \"グローバルICT市場の国・地域別シェアの推計（カテゴリー別）（2023年）において、クラウドの米国シェアは？\",\n",
    "    \"海底ケーブルの使用帯域幅の推移において、コンテンツプロバイダーはどのように遷移していますか？\",\n",
    "    \"日本のデータセンターサービス市場規模（売上高）の推移予測において、前年比成長率はどのように遷移していますか？\",\n",
    "    \"世界のICT市場における時価総額上位15社の変遷において、2025年に向上した企業を教えてもらえますか？\",\n",
    "    \"我が国の周波数帯ごとの主な用途と電波の特徴の図は何を表していますか？\",\n",
    "    \"衛星・HAPSによる通信サービスの提供イメージの図は何を表していますか？\",\n",
    "    \"日本のデータセンターの設置状況（地域別サーバールーム面積）において100,000㎡以上の地域はどこですか？\"\n",
    "]\n",
    "\n",
    "import time\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "print(f\"=== 開始: {len(queries)}件の質問を処理します ===\\n\")\n",
    "\n",
    "for i, q in enumerate(queries, 1):\n",
    "    print(\"=\"*80)\n",
    "    print(f\"【{i}/{len(queries)}】質問: {q}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    res = qa.answer_question(q, top_k=5, max_new_tokens=300)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    print(\"【回答】\")\n",
    "    print(res[\"answer\"])\n",
    "    print(f\"\\n【参照ソース】\")\n",
    "    for src in res[\"sources\"]:\n",
    "        print(f\"- {src['pdf_name']} ページ{src['page_num']} (スコア:{src['score']:.3f})\")\n",
    "    \n",
    "    print(f\"\\n処理時間: {elapsed_time:.2f}秒\")\n",
    "    print(f\"進捗: {i}/{len(queries)} 完了 ({100*i/len(queries):.1f}%)\")\n",
    "    print()\n",
    "\n",
    "print(\" 全ての質問の処理が完了しました\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87632b0f-bfaa-4ad7-9d75-fc3d3ca4f2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
